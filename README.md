# XGBoost_Fraud_Detection

This project focuses on detecting fraudulent financial transactions using the XGBoost classifier. Fraud detection is a highly imbalanced classification problem, and this model was trained to accurately identify fraudulent transactions while minimizing false negatives.

The goal is to build a high-performance model capable of distinguishing between fraud and non-fraud transactions.

# Objectives

Detect fraudulent transactions

Handle imbalanced dataset

Optimize recall for fraud cases

Evaluate model performance using appropriate metrics

# Technologies Used

Python

Pandas

NumPy

Scikit-learn

XGBoost

Matplotlib

Seaborn

# Model Used

XGBoost Classifier

# Why XGBoost?

Handles imbalanced data effectively

High performance and accuracy

Regularization to prevent overfitting

Fast and scalable

# Evaluation Metrics

Since fraud detection is imbalanced, the following metrics were used:

Precision

Recall

F1-Score

ROC-AUC Score

Precision-Recall Curve

Confusion Matrix

# Project Workflow

Data Cleaning

Exploratory Data Analysis (EDA)

Feature Engineering

Handling Class Imbalance

Model Training with XGBoost

Hyperparameter Tuning

Model Evaluation

# Key Results

Achieved strong fraud detection recall

Reduced false negatives

High ROC-AUC score

XGBoost performed efficiently on imbalanced data
